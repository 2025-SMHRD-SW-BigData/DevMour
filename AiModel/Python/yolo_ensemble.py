import torch
import numpy as np
from ultralytics import YOLO
from torchvision.ops import nms
from typing import List, Dict, Tuple, Optional
import logging
import sys
from pathlib import Path

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from config import MODEL_PATHS, MODEL_CONFIG, CLASS_NAMES, CLASS_MAPPING

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class YOLOEnsemble:
    """YOLO ì•™ìƒë¸” ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.models = []
        self.model_names = []
        self.weights = MODEL_CONFIG['ensemble_weights']

        self.nms_iou_threshold = MODEL_CONFIG['nms_iou_threshold']
        self.conf_threshold = MODEL_CONFIG.get('confidence_threshold', 0.25)  # ê¸°ë³¸ê°’ 0.25
        
        self._load_models()
    
    def _load_models(self):
        """ëª¨ë“  YOLO ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        logger.info("ğŸ” YOLO ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        for name, path in MODEL_PATHS.items():
            try:
                if path.exists():
                    model = YOLO(str(path))
                    self.models.append(model)
                    self.model_names.append(name)
                    logger.info(f"âœ”ï¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {name} ({path})")
                else:
                    logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {path}")
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {name} - {e}")
        
        if not self.models:
            raise RuntimeError("ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ì´ {len(self.models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def predict(self, image: np.ndarray) -> List[Dict]:
        """ì´ë¯¸ì§€ì— ëŒ€í•´ ì•™ìƒë¸” ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        logger.info("ğŸš€ YOLO ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘")
        logger.info(f"ğŸ“Š ì„¤ì •ê°’ - ì‹ ë¢°ë„ ì„ê³„ê°’: {self.conf_threshold}, NMS IoU ì„ê³„ê°’: {self.nms_iou_threshold}")
        logger.info(f"âš–ï¸ ì•™ìƒë¸” ê°€ì¤‘ì¹˜: {self.weights}")
        
        all_detections = []
        
        for i, model in enumerate(self.models):
            try:
                logger.info(f"ğŸ” ëª¨ë¸ {self.model_names[i]} ì˜ˆì¸¡ ì¤‘... (ê°€ì¤‘ì¹˜: {self.weights[i]})")
                
                # ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
                results = model(image, conf=self.conf_threshold, verbose=False)[0]
                
                if results.boxes is not None and len(results.boxes.xyxy) > 0:
                    detections = self._process_model_results(
                        results, i, self.model_names[i]
                    )
                    all_detections.extend(detections)
                    logger.info(f"âœ… ëª¨ë¸ {self.model_names[i]}: {len(detections)}ê°œ ê°ì²´ íƒì§€")
                else:
                    logger.info(f"âš ï¸ ëª¨ë¸ {self.model_names[i]}: íƒì§€ëœ ê°ì²´ ì—†ìŒ")
                    
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ {self.model_names[i]} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ğŸ“ˆ ì´ íƒì§€ëœ ê°ì²´: {len(all_detections)}ê°œ")
        
        # ì•™ìƒë¸” ê²°ê³¼ í†µí•© ë° NMS ì ìš©
        final_detections = self._ensemble_nms(all_detections)
        
        logger.info(f"ğŸ¯ NMS ì ìš© í›„ ìµœì¢… ê°ì²´: {len(final_detections)}ê°œ")
        return final_detections
    
    def _process_model_results(self, results, model_idx: int, model_name: str) -> List[Dict]:
        """ê°œë³„ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        detections = []
        
        boxes = results.boxes.xyxy.cpu().float()
        scores = results.boxes.conf.cpu().float()
        class_ids = results.boxes.cls.cpu().float()
        
        logger.info(f"ğŸ“Š ëª¨ë¸ {model_name} ì›ì‹œ ê²°ê³¼: {len(boxes)}ê°œ ë°•ìŠ¤, {len(scores)}ê°œ ì ìˆ˜, {len(class_ids)}ê°œ í´ë˜ìŠ¤")
        
        # model3 (yolov8s)ì˜ ê²½ìš° í´ë˜ìŠ¤ ë§¤í•‘ ì ìš©
        if model_name == 'yolov8s':
            logger.info(f"ğŸ”„ yolov8s í´ë˜ìŠ¤ ë§¤í•‘ ì ìš© ì „: {class_ids.tolist()}")
            class_ids = self._remap_classes(class_ids)
            logger.info(f"ğŸ”„ yolov8s í´ë˜ìŠ¤ ë§¤í•‘ ì ìš© í›„: {class_ids.tolist()}")
        
        for i in range(len(boxes)):
            if class_ids[i] >= 0:  # ìœ íš¨í•œ í´ë˜ìŠ¤ì¸ ê²½ìš°ë§Œ
                detection = {
                    'bbox': boxes[i].tolist(),
                    'score': scores[i].item(),
                    'class_id': int(class_ids[i].item()),
                    'class_name': CLASS_NAMES['final'][int(class_ids[i].item())],
                    'model_name': model_name,
                    'weight': self.weights[model_idx]
                }
                detections.append(detection)
                
                logger.info(f"ğŸ¯ ê°ì²´ {i+1}: {detection['class_name']} (ì‹ ë¢°ë„: {detection['score']:.3f}, ê°€ì¤‘ì¹˜: {detection['weight']:.2f})")
                logger.info(f"   ğŸ“ ìœ„ì¹˜: ({detection['bbox'][0]:.1f}, {detection['bbox'][1]:.1f}) ~ ({detection['bbox'][2]:.1f}, {detection['bbox'][3]:.1f})")
        
        return detections
    
    def _remap_classes(self, class_ids: torch.Tensor) -> torch.Tensor:
        """model3ì˜ ë¡œì»¬ í´ë˜ìŠ¤ë¥¼ ìµœì¢… í´ë˜ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        remapped_ids = torch.full_like(class_ids, -1.0)
        
        for local_name, final_name in CLASS_MAPPING.items():
            local_idx = CLASS_NAMES['model3_local'].index(local_name)
            final_idx = CLASS_NAMES['final'].index(final_name)
            
            mask = (class_ids == local_idx)
            remapped_ids[mask] = final_idx
        
        return remapped_ids
    
    def _ensemble_nms(self, detections: List[Dict]) -> List[Dict]:
        """ì•™ìƒë¸” ê²°ê³¼ì— NMSë¥¼ ì ìš©í•©ë‹ˆë‹¤."""
        if not detections:
            logger.info("âš ï¸ NMS ì ìš©í•  íƒì§€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        logger.info(f"ğŸ” NMS ì ìš© ì‹œì‘: ì´ {len(detections)}ê°œ íƒì§€ ê²°ê³¼")
        
        # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
        class_groups = {}
        for det in detections:
            class_id = det['class_id']
            if class_id not in class_groups:
                class_groups[class_id] = []
            class_groups[class_id].append(det)
        
        logger.info(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ê·¸ë£¹í™”: {len(class_groups)}ê°œ í´ë˜ìŠ¤")
        for class_id, class_dets in class_groups.items():
            class_name = CLASS_NAMES['final'][class_id]
            logger.info(f"   ğŸ“‹ {class_name}: {len(class_dets)}ê°œ íƒì§€")
        
        final_detections = []
        
        for class_id, class_dets in class_groups.items():
            class_name = CLASS_NAMES['final'][class_id]
            logger.info(f"ğŸ¯ í´ë˜ìŠ¤ '{class_name}' NMS ì²˜ë¦¬ ì¤‘...")
            
            if len(class_dets) == 1:
                logger.info(f"   âœ… ë‹¨ì¼ íƒì§€: {class_name} ì¶”ê°€")
                final_detections.append(class_dets[0])
                continue
            
            logger.info(f"   ğŸ”„ {len(class_dets)}ê°œ ì¤‘ë³µ íƒì§€ - ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚° ë° NMS ì ìš©")
            
            # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°
            weighted_scores = []
            weighted_boxes = []
            
            for i, det in enumerate(class_dets):
                weight = det['weight']
                weighted_score = det['score'] * weight
                weighted_scores.append(weighted_score)
                weighted_boxes.append(det['bbox'])
                logger.info(f"      ğŸ“Š íƒì§€ {i+1}: ì›ë³¸ ì ìˆ˜ {det['score']:.3f} Ã— ê°€ì¤‘ì¹˜ {weight:.2f} = {weighted_score:.3f}")
            
            # NMS ì ìš©
            boxes_tensor = torch.tensor(weighted_boxes, dtype=torch.float32)
            scores_tensor = torch.tensor(weighted_scores, dtype=torch.float32)
            
            logger.info(f"   âœ‚ï¸ NMS ì ìš© (IoU ì„ê³„ê°’: {self.nms_iou_threshold})")
            keep_indices = nms(boxes_tensor, scores_tensor, self.nms_iou_threshold)
            
            logger.info(f"   ğŸ¯ NMS í›„ ìœ ì§€ëœ íƒì§€: {len(keep_indices)}ê°œ")
            for idx in keep_indices:
                final_detections.append(class_dets[idx])
                logger.info(f"      âœ… ìœ ì§€: {class_dets[idx]['class_name']} (ì‹ ë¢°ë„: {class_dets[idx]['score']:.3f})")
        
        logger.info(f"ğŸ‰ NMS ì™„ë£Œ: {len(detections)}ê°œ â†’ {len(final_detections)}ê°œ")
        return final_detections
    
    def calculate_risk_score(self, detections: List[Dict]) -> Dict:
        """íƒì§€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ„í—˜ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        from config import RISK_SCORES
        
        logger.info("ğŸ’° ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° ì‹œì‘")
        logger.info(f"ğŸ“Š ìœ„í—˜ë„ ì ìˆ˜ ì„¤ì •: {RISK_SCORES}")
        
        total_score = 0
        class_counts = {name: 0 for name in CLASS_NAMES['final']}
        
        for i, det in enumerate(detections):
            class_name = det['class_name']
            if class_name in RISK_SCORES:
                risk_score = RISK_SCORES[class_name]
                total_score += risk_score
                class_counts[class_name] += 1
                logger.info(f"ğŸ¯ ê°ì²´ {i+1}: {class_name} â†’ ìœ„í—˜ë„ ì ìˆ˜ +{risk_score} (ì´ì : {total_score})")
            else:
                logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤: {class_name} (ìœ„í—˜ë„ ì ìˆ˜ ì—†ìŒ)")
        
        logger.info(f"ğŸ“ˆ í´ë˜ìŠ¤ë³„ ê°œìˆ˜: {class_counts}")
        logger.info(f"ğŸ† ìµœì¢… ìœ„í—˜ë„ ì´ì : {total_score}")
        
        result = {
            'total_risk_score': total_score,
            'class_counts': class_counts,
            'detection_count': len(detections)
        }
        
        logger.info(f"âœ… ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {result}")
        return result
